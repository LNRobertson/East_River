{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa898ac",
   "metadata": {},
   "source": [
    "improved multi-pipe model\n",
    "\n",
    "- Enforces a 0–60/60–80/80–100 % train/val/test split\n",
    "- Uses early stopping on each horizon\n",
    "- Increases your TS splits to 5 for any future CV\n",
    "- Drops the MultiOutputRegressor in favor of one XGBRegressor per horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6098ee54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training 24h model with early stopping…\n",
      "[0]\tvalidation_0-rmse:58.81391\n",
      "[1]\tvalidation_0-rmse:44.11107\n",
      "[2]\tvalidation_0-rmse:33.84137\n",
      "[3]\tvalidation_0-rmse:26.89883\n",
      "[4]\tvalidation_0-rmse:22.90484\n",
      "[5]\tvalidation_0-rmse:20.10334\n",
      "[6]\tvalidation_0-rmse:18.13600\n",
      "[7]\tvalidation_0-rmse:16.88642\n",
      "[8]\tvalidation_0-rmse:16.33261\n",
      "[9]\tvalidation_0-rmse:15.89845\n",
      "[10]\tvalidation_0-rmse:15.44428\n",
      "[11]\tvalidation_0-rmse:15.20904\n",
      "[12]\tvalidation_0-rmse:15.04896\n",
      "[13]\tvalidation_0-rmse:14.88466\n",
      "[14]\tvalidation_0-rmse:14.72364\n",
      "[15]\tvalidation_0-rmse:14.67339\n",
      "[16]\tvalidation_0-rmse:14.59535\n",
      "[17]\tvalidation_0-rmse:14.53109\n",
      "[18]\tvalidation_0-rmse:14.50058\n",
      "[19]\tvalidation_0-rmse:14.52294\n",
      "[20]\tvalidation_0-rmse:14.47883\n",
      "[21]\tvalidation_0-rmse:14.40865\n",
      "[22]\tvalidation_0-rmse:14.41199\n",
      "[23]\tvalidation_0-rmse:14.37252\n",
      "[24]\tvalidation_0-rmse:14.36456\n",
      "[25]\tvalidation_0-rmse:14.32017\n",
      "[26]\tvalidation_0-rmse:14.26101\n",
      "[27]\tvalidation_0-rmse:14.22164\n",
      "[28]\tvalidation_0-rmse:14.14699\n",
      "[29]\tvalidation_0-rmse:14.11098\n",
      "[30]\tvalidation_0-rmse:14.09342\n",
      "[31]\tvalidation_0-rmse:14.08414\n",
      "[32]\tvalidation_0-rmse:14.03647\n",
      "[33]\tvalidation_0-rmse:14.03752\n",
      "[34]\tvalidation_0-rmse:14.03693\n",
      "[35]\tvalidation_0-rmse:14.01325\n",
      "[36]\tvalidation_0-rmse:13.99512\n",
      "[37]\tvalidation_0-rmse:14.01442\n",
      "[38]\tvalidation_0-rmse:13.99180\n",
      "[39]\tvalidation_0-rmse:13.95113\n",
      "[40]\tvalidation_0-rmse:13.93436\n",
      "[41]\tvalidation_0-rmse:14.00403\n",
      "[42]\tvalidation_0-rmse:14.00565\n",
      "[43]\tvalidation_0-rmse:14.00237\n",
      "[44]\tvalidation_0-rmse:14.01944\n",
      "[45]\tvalidation_0-rmse:14.00884\n",
      "[46]\tvalidation_0-rmse:14.01686\n",
      "[47]\tvalidation_0-rmse:13.99993\n",
      "[48]\tvalidation_0-rmse:13.99110\n",
      "[49]\tvalidation_0-rmse:13.97769\n",
      "[50]\tvalidation_0-rmse:13.95947\n",
      "[51]\tvalidation_0-rmse:13.95126\n",
      "[52]\tvalidation_0-rmse:13.94763\n",
      "[53]\tvalidation_0-rmse:13.93877\n",
      "[54]\tvalidation_0-rmse:13.95164\n",
      "[55]\tvalidation_0-rmse:13.93426\n",
      "[56]\tvalidation_0-rmse:13.91494\n",
      "[57]\tvalidation_0-rmse:13.91482\n",
      "[58]\tvalidation_0-rmse:13.93052\n",
      "[59]\tvalidation_0-rmse:13.91288\n",
      "[60]\tvalidation_0-rmse:13.88933\n",
      "[61]\tvalidation_0-rmse:13.86332\n",
      "[62]\tvalidation_0-rmse:13.86177\n",
      "[63]\tvalidation_0-rmse:13.93027\n",
      "[64]\tvalidation_0-rmse:13.92761\n",
      "[65]\tvalidation_0-rmse:13.92037\n",
      "[66]\tvalidation_0-rmse:13.89905\n",
      "[67]\tvalidation_0-rmse:13.89427\n",
      "[68]\tvalidation_0-rmse:13.88810\n",
      "[69]\tvalidation_0-rmse:13.88491\n",
      "[70]\tvalidation_0-rmse:13.89524\n",
      "[71]\tvalidation_0-rmse:13.89800\n",
      "[72]\tvalidation_0-rmse:13.89864\n",
      "[73]\tvalidation_0-rmse:13.89477\n",
      "[74]\tvalidation_0-rmse:13.88591\n",
      "[75]\tvalidation_0-rmse:13.88873\n",
      "[76]\tvalidation_0-rmse:13.88488\n",
      "[77]\tvalidation_0-rmse:13.88123\n",
      "[78]\tvalidation_0-rmse:13.82664\n",
      "[79]\tvalidation_0-rmse:13.82359\n",
      "[80]\tvalidation_0-rmse:13.81687\n",
      "[81]\tvalidation_0-rmse:13.81172\n",
      "[82]\tvalidation_0-rmse:13.80169\n",
      "[83]\tvalidation_0-rmse:13.78291\n",
      "[84]\tvalidation_0-rmse:13.78594\n",
      "[85]\tvalidation_0-rmse:13.75779\n",
      "[86]\tvalidation_0-rmse:13.75098\n",
      "[87]\tvalidation_0-rmse:13.75323\n",
      "[88]\tvalidation_0-rmse:13.74828\n",
      "[89]\tvalidation_0-rmse:13.73268\n",
      "[90]\tvalidation_0-rmse:13.72873\n",
      "[91]\tvalidation_0-rmse:13.72690\n",
      "[92]\tvalidation_0-rmse:13.72489\n",
      "[93]\tvalidation_0-rmse:13.72209\n",
      "[94]\tvalidation_0-rmse:13.71201\n",
      "[95]\tvalidation_0-rmse:13.71527\n",
      "[96]\tvalidation_0-rmse:13.71583\n",
      "[97]\tvalidation_0-rmse:13.71870\n",
      "[98]\tvalidation_0-rmse:13.71874\n",
      "[99]\tvalidation_0-rmse:13.71386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Linds\\anaconda3\\envs\\load_forecasting_env\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ⇒ 24h HO MAE: 10.72, RMSE: 14.77\n",
      "\n",
      "Training 48h model with early stopping…\n",
      "[0]\tvalidation_0-rmse:59.00020\n",
      "[1]\tvalidation_0-rmse:44.26427\n",
      "[2]\tvalidation_0-rmse:34.18180\n",
      "[3]\tvalidation_0-rmse:27.37007\n",
      "[4]\tvalidation_0-rmse:22.82072\n",
      "[5]\tvalidation_0-rmse:20.03945\n",
      "[6]\tvalidation_0-rmse:17.91239\n",
      "[7]\tvalidation_0-rmse:16.84052\n",
      "[8]\tvalidation_0-rmse:16.14281\n",
      "[9]\tvalidation_0-rmse:15.76717\n",
      "[10]\tvalidation_0-rmse:15.40760\n",
      "[11]\tvalidation_0-rmse:15.20719\n",
      "[12]\tvalidation_0-rmse:15.04820\n",
      "[13]\tvalidation_0-rmse:14.86596\n",
      "[14]\tvalidation_0-rmse:14.71354\n",
      "[15]\tvalidation_0-rmse:14.63077\n",
      "[16]\tvalidation_0-rmse:14.54311\n",
      "[17]\tvalidation_0-rmse:14.48943\n",
      "[18]\tvalidation_0-rmse:14.44174\n",
      "[19]\tvalidation_0-rmse:14.42697\n",
      "[20]\tvalidation_0-rmse:14.38588\n",
      "[21]\tvalidation_0-rmse:14.38443\n",
      "[22]\tvalidation_0-rmse:14.38848\n",
      "[23]\tvalidation_0-rmse:14.35986\n",
      "[24]\tvalidation_0-rmse:14.36405\n",
      "[25]\tvalidation_0-rmse:14.38544\n",
      "[26]\tvalidation_0-rmse:14.37333\n",
      "[27]\tvalidation_0-rmse:14.37477\n",
      "[28]\tvalidation_0-rmse:14.38941\n",
      "[29]\tvalidation_0-rmse:14.32806\n",
      "[30]\tvalidation_0-rmse:14.27858\n",
      "[31]\tvalidation_0-rmse:14.25502\n",
      "[32]\tvalidation_0-rmse:14.21889\n",
      "[33]\tvalidation_0-rmse:14.18762\n",
      "[34]\tvalidation_0-rmse:14.15658\n",
      "[35]\tvalidation_0-rmse:14.13223\n",
      "[36]\tvalidation_0-rmse:14.12617\n",
      "[37]\tvalidation_0-rmse:14.10896\n",
      "[38]\tvalidation_0-rmse:14.09774\n",
      "[39]\tvalidation_0-rmse:14.14396\n",
      "[40]\tvalidation_0-rmse:14.10391\n",
      "[41]\tvalidation_0-rmse:14.08361\n",
      "[42]\tvalidation_0-rmse:14.07555\n",
      "[43]\tvalidation_0-rmse:14.04861\n",
      "[44]\tvalidation_0-rmse:14.01042\n",
      "[45]\tvalidation_0-rmse:13.99345\n",
      "[46]\tvalidation_0-rmse:13.98600\n",
      "[47]\tvalidation_0-rmse:13.97601\n",
      "[48]\tvalidation_0-rmse:13.96561\n",
      "[49]\tvalidation_0-rmse:13.94926\n",
      "[50]\tvalidation_0-rmse:13.92994\n",
      "[51]\tvalidation_0-rmse:13.92063\n",
      "[52]\tvalidation_0-rmse:13.89490\n",
      "[53]\tvalidation_0-rmse:13.90141\n",
      "[54]\tvalidation_0-rmse:14.02490\n",
      "[55]\tvalidation_0-rmse:14.05863\n",
      "[56]\tvalidation_0-rmse:14.05185\n",
      "[57]\tvalidation_0-rmse:14.04887\n",
      "[58]\tvalidation_0-rmse:14.07062\n",
      "[59]\tvalidation_0-rmse:14.04956\n",
      "[60]\tvalidation_0-rmse:14.04482\n",
      "[61]\tvalidation_0-rmse:14.03374\n",
      "[62]\tvalidation_0-rmse:14.02703\n",
      "[63]\tvalidation_0-rmse:14.03685\n",
      "[64]\tvalidation_0-rmse:14.02070\n",
      "[65]\tvalidation_0-rmse:14.03254\n",
      "[66]\tvalidation_0-rmse:14.00839\n",
      "[67]\tvalidation_0-rmse:13.98818\n",
      "[68]\tvalidation_0-rmse:13.97907\n",
      "[69]\tvalidation_0-rmse:13.96005\n",
      "[70]\tvalidation_0-rmse:13.91971\n",
      "[71]\tvalidation_0-rmse:13.92705\n",
      "[72]\tvalidation_0-rmse:13.93729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Linds\\anaconda3\\envs\\load_forecasting_env\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ⇒ 48h HO MAE: 11.25, RMSE: 15.27\n",
      "\n",
      "Training 72h model with early stopping…\n",
      "[0]\tvalidation_0-rmse:59.04976\n",
      "[1]\tvalidation_0-rmse:44.54137\n",
      "[2]\tvalidation_0-rmse:34.38589\n",
      "[3]\tvalidation_0-rmse:27.73975\n",
      "[4]\tvalidation_0-rmse:23.50458\n",
      "[5]\tvalidation_0-rmse:20.47273\n",
      "[6]\tvalidation_0-rmse:18.63962\n",
      "[7]\tvalidation_0-rmse:17.55136\n",
      "[8]\tvalidation_0-rmse:16.67464\n",
      "[9]\tvalidation_0-rmse:16.34665\n",
      "[10]\tvalidation_0-rmse:15.86827\n",
      "[11]\tvalidation_0-rmse:15.47255\n",
      "[12]\tvalidation_0-rmse:15.35867\n",
      "[13]\tvalidation_0-rmse:15.21923\n",
      "[14]\tvalidation_0-rmse:15.14526\n",
      "[15]\tvalidation_0-rmse:15.03896\n",
      "[16]\tvalidation_0-rmse:14.99063\n",
      "[17]\tvalidation_0-rmse:14.94299\n",
      "[18]\tvalidation_0-rmse:14.92332\n",
      "[19]\tvalidation_0-rmse:14.90095\n",
      "[20]\tvalidation_0-rmse:14.86686\n",
      "[21]\tvalidation_0-rmse:14.82677\n",
      "[22]\tvalidation_0-rmse:14.71610\n",
      "[23]\tvalidation_0-rmse:14.75014\n",
      "[24]\tvalidation_0-rmse:14.72893\n",
      "[25]\tvalidation_0-rmse:14.69404\n",
      "[26]\tvalidation_0-rmse:14.68469\n",
      "[27]\tvalidation_0-rmse:14.68273\n",
      "[28]\tvalidation_0-rmse:14.67756\n",
      "[29]\tvalidation_0-rmse:14.67879\n",
      "[30]\tvalidation_0-rmse:14.67244\n",
      "[31]\tvalidation_0-rmse:14.67218\n",
      "[32]\tvalidation_0-rmse:14.65278\n",
      "[33]\tvalidation_0-rmse:14.60005\n",
      "[34]\tvalidation_0-rmse:14.62763\n",
      "[35]\tvalidation_0-rmse:14.62617\n",
      "[36]\tvalidation_0-rmse:14.61466\n",
      "[37]\tvalidation_0-rmse:14.60770\n",
      "[38]\tvalidation_0-rmse:14.60764\n",
      "[39]\tvalidation_0-rmse:14.60902\n",
      "[40]\tvalidation_0-rmse:14.60635\n",
      "[41]\tvalidation_0-rmse:14.61045\n",
      "[42]\tvalidation_0-rmse:14.64595\n",
      "[43]\tvalidation_0-rmse:14.61128\n",
      "[44]\tvalidation_0-rmse:14.60852\n",
      "[45]\tvalidation_0-rmse:14.60772\n",
      "[46]\tvalidation_0-rmse:14.59206\n",
      "[47]\tvalidation_0-rmse:14.57436\n",
      "[48]\tvalidation_0-rmse:14.54067\n",
      "[49]\tvalidation_0-rmse:14.53965\n",
      "[50]\tvalidation_0-rmse:14.52341\n",
      "[51]\tvalidation_0-rmse:14.52950\n",
      "[52]\tvalidation_0-rmse:14.52169\n",
      "[53]\tvalidation_0-rmse:14.50710\n",
      "[54]\tvalidation_0-rmse:14.49888\n",
      "[55]\tvalidation_0-rmse:14.48177\n",
      "[56]\tvalidation_0-rmse:14.46191\n",
      "[57]\tvalidation_0-rmse:14.46371\n",
      "[58]\tvalidation_0-rmse:14.46661\n",
      "[59]\tvalidation_0-rmse:14.47096\n",
      "[60]\tvalidation_0-rmse:14.43700\n",
      "[61]\tvalidation_0-rmse:14.43790\n",
      "[62]\tvalidation_0-rmse:14.42757\n",
      "[63]\tvalidation_0-rmse:14.40199\n",
      "[64]\tvalidation_0-rmse:14.36547\n",
      "[65]\tvalidation_0-rmse:14.35716\n",
      "[66]\tvalidation_0-rmse:14.35453\n",
      "[67]\tvalidation_0-rmse:14.35421\n",
      "[68]\tvalidation_0-rmse:14.35749\n",
      "[69]\tvalidation_0-rmse:14.35352\n",
      "[70]\tvalidation_0-rmse:14.34515\n",
      "[71]\tvalidation_0-rmse:14.35027\n",
      "[72]\tvalidation_0-rmse:14.36045\n",
      "[73]\tvalidation_0-rmse:14.33766\n",
      "[74]\tvalidation_0-rmse:14.33795\n",
      "[75]\tvalidation_0-rmse:14.33438\n",
      "[76]\tvalidation_0-rmse:14.34681\n",
      "[77]\tvalidation_0-rmse:14.31673\n",
      "[78]\tvalidation_0-rmse:14.31009\n",
      "[79]\tvalidation_0-rmse:14.30090\n",
      "[80]\tvalidation_0-rmse:14.29489\n",
      "[81]\tvalidation_0-rmse:14.28697\n",
      "[82]\tvalidation_0-rmse:14.28674\n",
      "[83]\tvalidation_0-rmse:14.28289\n",
      "[84]\tvalidation_0-rmse:14.27914\n",
      "[85]\tvalidation_0-rmse:14.27337\n",
      "[86]\tvalidation_0-rmse:14.26142\n",
      "[87]\tvalidation_0-rmse:14.25612\n",
      "[88]\tvalidation_0-rmse:14.25301\n",
      "[89]\tvalidation_0-rmse:14.25107\n",
      "[90]\tvalidation_0-rmse:14.26897\n",
      "[91]\tvalidation_0-rmse:14.26971\n",
      "[92]\tvalidation_0-rmse:14.26866\n",
      "[93]\tvalidation_0-rmse:14.27920\n",
      "[94]\tvalidation_0-rmse:14.28690\n",
      "[95]\tvalidation_0-rmse:14.27693\n",
      "[96]\tvalidation_0-rmse:14.26815\n",
      "[97]\tvalidation_0-rmse:14.27330\n",
      "[98]\tvalidation_0-rmse:14.27901\n",
      "[99]\tvalidation_0-rmse:14.27806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Linds\\anaconda3\\envs\\load_forecasting_env\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ⇒ 72h HO MAE: 11.72, RMSE: 16.05\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports & Config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import joblib\n",
    "\n",
    "DATA_PATH    = r\"C:\\Users\\Linds\\Repos\\East_River\\data\\training\\east_river_training-v2.h5\"\n",
    "HORIZONS     = [24, 48, 72]\n",
    "TS_CV        = TimeSeriesSplit(n_splits=5)             # increased folds\n",
    "MODEL_PARAMS = dict(\n",
    "    tree_method='hist',\n",
    "    random_state=0,\n",
    "    verbosity=0,\n",
    "    eval_metric='rmse',\n",
    "    early_stopping_rounds=20                         # early stopping\n",
    ")\n",
    "\n",
    "# 2. Load preprocessed data (unchanged)\n",
    "def load_data(path):\n",
    "    return pd.read_hdf(path, key='df')\n",
    "\n",
    "# 3. Prepare X & multi‑output y (unchanged)\n",
    "def prepare(df):\n",
    "    drop_cols = [\n",
    "        'local_time','last_control_time',\n",
    "        'OnLine_Load_MW','Load_Control_MW','Control_Threshold_MW'\n",
    "    ] + [f'y_plus_{h}h' for h in HORIZONS]\n",
    "    feats = [c for c in df.columns if c not in drop_cols]\n",
    "    X = df[feats].drop(columns=['location'], errors='ignore')\n",
    "    y = df[[f'y_plus_{h}h' for h in HORIZONS]]\n",
    "    return X, y\n",
    "\n",
    "# 4. Train & evaluate per‑horizon XGB with clear chronology + early‑stop\n",
    "def run_multi():\n",
    "    df = load_data(DATA_PATH)\n",
    "    X, y = prepare(df)\n",
    "\n",
    "    n = len(X)\n",
    "    train_end = int(0.6 * n)\n",
    "    val_end   = int(0.8 * n)\n",
    "\n",
    "    X_tr,  X_val, X_ho = X.iloc[:train_end], X.iloc[train_end:val_end], X.iloc[val_end:]\n",
    "    y_tr,  y_val, y_ho = y.iloc[:train_end], y.iloc[train_end:val_end], y.iloc[val_end:]\n",
    "\n",
    "    models = {}\n",
    "    y_pred  = np.zeros_like(y_ho.values)\n",
    "\n",
    "    for idx, h in enumerate(HORIZONS):\n",
    "        print(f\"\\nTraining {h}h model with early stopping…\")\n",
    "        m = XGBRegressor(**MODEL_PARAMS)\n",
    "        m.fit(\n",
    "            X_tr, y_tr.iloc[:, idx],\n",
    "            eval_set=[(X_val, y_val.iloc[:, idx])]\n",
    "        )\n",
    "        models[h]     = m\n",
    "        y_pred[:, idx] = m.predict(X_ho)\n",
    "\n",
    "        mae  = mean_absolute_error(y_ho.iloc[:,idx], y_pred[:,idx])\n",
    "        rmse = mean_squared_error(y_ho.iloc[:,idx], y_pred[:,idx], squared=False)\n",
    "        print(f\" ⇒ {h}h HO MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
    "\n",
    "    joblib.dump(models, \"xgb_multi_horizon_models.pkl\")\n",
    "    return models\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    models = run_multi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64339e17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# reload data & split\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mprepare\u001b[49m(df)\n\u001b[0;32m      4\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(X))\n\u001b[0;32m      5\u001b[0m X_ho \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[split:]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prepare' is not defined"
     ]
    }
   ],
   "source": [
    "# reload data & split\n",
    "#\n",
    "X, y = prepare(df)\n",
    "split = int(0.8 * len(X))\n",
    "X_ho = X.iloc[split:]\n",
    "y_ho = y.iloc[split:]\n",
    "\n",
    "# load the dict of horizon→model\n",
    "models = joblib.load(\"xgb_multi_horizon_models.pkl\")\n",
    "\n",
    "fig, axes = plt.subplots(len(HORIZONS), 3, figsize=(15, 5 * len(HORIZONS)))\n",
    "\n",
    "for i, h in enumerate(HORIZONS):\n",
    "    model = models[h]\n",
    "    y_true = y_ho.iloc[:, i]\n",
    "    y_pred = model.predict(X_ho)\n",
    "    resid = y_true - y_pred\n",
    "\n",
    "    # 1) Residual histogram\n",
    "    ax = axes[i, 0]\n",
    "    ax.hist(resid, bins=50, edgecolor='k')\n",
    "    ax.set_title(f\"{h}h Residuals\")\n",
    "    ax.set_xlabel(\"Error (True – Pred)\")\n",
    "\n",
    "    # 2) Actual vs Pred scatter\n",
    "    ax = axes[i, 1]\n",
    "    ax.scatter(y_true, y_pred, alpha=0.3)\n",
    "    mn, mx = y_true.min(), y_true.max()\n",
    "    ax.plot([mn, mx], [mn, mx], 'r--')\n",
    "    ax.set_title(f\"{h}h Actual vs Pred\")\n",
    "    ax.set_xlabel(\"True\")\n",
    "    ax.set_ylabel(\"Pred\")\n",
    "\n",
    "    # 3) Top‑10 feature importance\n",
    "    ax = axes[i, 2]\n",
    "    fi = pd.Series(model.feature_importances_, index=X_ho.columns)\n",
    "    top10 = fi.nlargest(10).sort_values()\n",
    "    ax.barh(top10.index, top10.values, edgecolor='k')\n",
    "    ax.set_title(f\"{h}h Top‑10 Features\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe01ea47",
   "metadata": {},
   "source": [
    "Inital multi-pipe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453f94a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Linds\\anaconda3\\envs\\load_forecasting_env\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Linds\\anaconda3\\envs\\load_forecasting_env\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Linds\\anaconda3\\envs\\load_forecasting_env\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24h — HO MAE: 9.54, RMSE: 13.03\n",
      "48h — HO MAE: 10.01, RMSE: 13.59\n",
      "72h — HO MAE: 10.36, RMSE: 13.97\n",
      "CV MAE: 12.017614023724285\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports & Config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate\n",
    "import joblib\n",
    "\n",
    "DATA_PATH    = r\"C:\\Users\\Linds\\Repos\\East_River\\data\\training\\east_river_training-v2.h5\"\n",
    "HORIZONS     = [24, 48, 72]\n",
    "TS_CV        = TimeSeriesSplit(n_splits=3)\n",
    "MODEL_PARAMS = dict(tree_method='hist', random_state=0)\n",
    "\n",
    "# 2. Load preprocessed data\n",
    "def load_data(path):\n",
    "    return pd.read_hdf(path, key='df')\n",
    "\n",
    "# 3. Prepare X & multi‑output y\n",
    "def prepare(df):\n",
    "    drop_cols = [\n",
    "        'local_time','last_control_time',\n",
    "        'OnLine_Load_MW','Load_Control_MW','Control_Threshold_MW'\n",
    "    ] + [f'y_plus_{h}h' for h in HORIZONS]\n",
    "    feats = [c for c in df.columns if c not in drop_cols]\n",
    "    X = df[feats].drop(columns=['location'], errors='ignore')\n",
    "    y = df[[f'y_plus_{h}h' for h in HORIZONS]]\n",
    "    return X, y\n",
    "\n",
    "# 4. Train & evaluate multi‑output model\n",
    "def run_multi():\n",
    "    df = load_data(DATA_PATH)\n",
    "    X, y = prepare(df)\n",
    "    split = int(0.8 * len(X))\n",
    "    X_tr, X_ho = X.iloc[:split], X.iloc[split:]\n",
    "    y_tr, y_ho = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "    mor = MultiOutputRegressor(XGBRegressor(**MODEL_PARAMS), n_jobs=1)\n",
    "    # cross‑validate each output\n",
    "    cv = cross_validate(mor, X_tr, y_tr, cv=TS_CV,\n",
    "                        scoring=['neg_mean_absolute_error','neg_root_mean_squared_error'],\n",
    "                        n_jobs=1)\n",
    "    mor.fit(X_tr, y_tr)\n",
    "    y_pred = mor.predict(X_ho)\n",
    "\n",
    "    # per‑horizon metrics\n",
    "    for idx, h in enumerate(HORIZONS):\n",
    "        mae  = mean_absolute_error(y_ho.iloc[:,idx], y_pred[:,idx])\n",
    "        rmse = mean_squared_error(y_ho.iloc[:,idx], y_pred[:,idx], squared=False)\n",
    "        print(f\"{h}h — HO MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
    "\n",
    "    joblib.dump(mor, \"xgb_multi_horizon.pkl\")\n",
    "    return mor, cv\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, cv_res = run_multi()\n",
    "    print(\"CV MAE:\", -cv_res['test_neg_mean_absolute_error'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba6a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAE:  12.017614023724285\n",
      "CV RMSE: 17.014191543957047\n"
     ]
    }
   ],
   "source": [
    "# print both CV MAE and CV RMSE\n",
    "print(\"CV MAE: \", -cv_res['test_neg_mean_absolute_error'].mean())\n",
    "print(\"CV RMSE:\", -cv_res['test_neg_root_mean_squared_error'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8469f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Compare against existing Control_Threshold logic\n",
    "import joblib\n",
    "df_full = pd.read_hdf(DATA_PATH, key='df')  # raw v2 includes actual & threshold\n",
    "print(\"\\n=== Hold‑out: Forecast vs Threshold ===\")\n",
    "for h in HORIZONS:\n",
    "    # align actual & threshold for H‑hour ahead\n",
    "    actual = df_full['OnLine_Load_MW'].shift(-h).dropna().iloc[split:]\n",
    "    threshold = df_full['Control_Threshold_MW'].shift(-h).dropna().iloc[split:]\n",
    "    # load your saved model and predict on the same hold‑out X\n",
    "    model = joblib.load(f\"xgb_v2_{h}h.pkl\")\n",
    "    y_pred = model.predict(X.iloc[split:])\n",
    "    # compute MAEs\n",
    "    mae_f = mean_absolute_error(actual, y_pred)\n",
    "    mae_t = mean_absolute_error(actual, threshold)\n",
    "    imp  = (mae_t - mae_f) / mae_t * 100\n",
    "    print(f\"{h}h — MAE(threshold)={mae_t:.2f}, MAE(forecast)={mae_f:.2f}, Δ={imp:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "load_forecasting_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
